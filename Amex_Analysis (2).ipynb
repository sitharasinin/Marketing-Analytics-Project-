{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8e6fbf91-9168-41e5-82ad-9f5b47c1150b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c91d7074-ae10-42ea-baf0-6d896941a11b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "07a3664b-0b18-47ad-ac60-608514c205ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\drism\n"
     ]
    }
   ],
   "source": [
    "print(os.getcwd())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "11a4be73-4a39-4cf5-9a35-8e177a8e4fa3",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('C:/Users/drism/Documents/Amex_Project/data/amex_data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "bb433292-c960-4eac-80c7-7f1c65ef5790",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>customer_id</th>\n",
       "      <th>offer_id</th>\n",
       "      <th>event_ts</th>\n",
       "      <th>event_dt</th>\n",
       "      <th>offer_action</th>\n",
       "      <th>var_1</th>\n",
       "      <th>var_2</th>\n",
       "      <th>var_3</th>\n",
       "      <th>var_4</th>\n",
       "      <th>var_5</th>\n",
       "      <th>...</th>\n",
       "      <th>var_41</th>\n",
       "      <th>var_42</th>\n",
       "      <th>var_43</th>\n",
       "      <th>var_44</th>\n",
       "      <th>var_45</th>\n",
       "      <th>var_46</th>\n",
       "      <th>var_47</th>\n",
       "      <th>var_48</th>\n",
       "      <th>var_49</th>\n",
       "      <th>var_50</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1010494</td>\n",
       "      <td>601711</td>\n",
       "      <td>2023-11-01 10:25:21.000904</td>\n",
       "      <td>2023-11-01 00:00:00</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>0.089583</td>\n",
       "      <td>0.083204</td>\n",
       "      <td>2151.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>True</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1010494</td>\n",
       "      <td>33452</td>\n",
       "      <td>2023-11-09 08:37:35.165000</td>\n",
       "      <td>2023-11-09 00:00:00</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>0.111752</td>\n",
       "      <td>0.181776</td>\n",
       "      <td>1668.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1010494</td>\n",
       "      <td>88456737</td>\n",
       "      <td>2023-11-01 10:15:55.000489</td>\n",
       "      <td>2023-11-01 00:00:00</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>0.088514</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1010494</td>\n",
       "      <td>390981</td>\n",
       "      <td>2023-11-01 10:27:27.000313</td>\n",
       "      <td>2023-11-01 00:00:00</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>0.086931</td>\n",
       "      <td>0.059246</td>\n",
       "      <td>3678.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>False</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1010494</td>\n",
       "      <td>7114</td>\n",
       "      <td>2023-11-09 08:37:38.553000</td>\n",
       "      <td>2023-11-09 00:00:00</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>0.089497</td>\n",
       "      <td>0.124221</td>\n",
       "      <td>3619.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>False</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 55 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   customer_id  offer_id                    event_ts             event_dt  \\\n",
       "0      1010494    601711  2023-11-01 10:25:21.000904  2023-11-01 00:00:00   \n",
       "1      1010494     33452  2023-11-09 08:37:35.165000  2023-11-09 00:00:00   \n",
       "2      1010494  88456737  2023-11-01 10:15:55.000489  2023-11-01 00:00:00   \n",
       "3      1010494    390981  2023-11-01 10:27:27.000313  2023-11-01 00:00:00   \n",
       "4      1010494      7114  2023-11-09 08:37:38.553000  2023-11-09 00:00:00   \n",
       "\n",
       "  offer_action  var_1  var_2  var_3  var_4  var_5  ...    var_41    var_42  \\\n",
       "0            1    NaN    NaN    NaN    NaN    NaN  ...  0.089583  0.083204   \n",
       "1            0    NaN    NaN    NaN    NaN    NaN  ...  0.111752  0.181776   \n",
       "2            1    NaN    NaN    NaN    NaN    NaN  ...  0.088514       NaN   \n",
       "3            1    NaN    NaN    NaN    NaN    NaN  ...  0.086931  0.059246   \n",
       "4            0    NaN    NaN    NaN    NaN    NaN  ...  0.089497  0.124221   \n",
       "\n",
       "   var_43  var_44  var_45  var_46  var_47  var_48  var_49  var_50  \n",
       "0  2151.0     0.0     0.0     0.0     0.0     0.0    True     0.0  \n",
       "1  1668.0     0.0     0.0     0.0     0.0     0.0     1.0     0.0  \n",
       "2     NaN     0.0     0.0     0.0     0.0     0.0     1.0     0.0  \n",
       "3  3678.0     0.0   False     0.0     0.0     0.0     1.0     0.0  \n",
       "4  3619.0     0.0     0.0     0.0   False     0.0     1.0     0.0  \n",
       "\n",
       "[5 rows x 55 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c9bf450d-28de-49e7-8ec1-09556d48fa2a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 2004812 entries, 0 to 2004811\n",
      "Data columns (total 55 columns):\n",
      " #   Column        Dtype  \n",
      "---  ------        -----  \n",
      " 0   customer_id   int64  \n",
      " 1   offer_id      int64  \n",
      " 2   event_ts      object \n",
      " 3   event_dt      object \n",
      " 4   offer_action  object \n",
      " 5   var_1         float64\n",
      " 6   var_2         float64\n",
      " 7   var_3         float64\n",
      " 8   var_4         float64\n",
      " 9   var_5         float64\n",
      " 10  var_6         float64\n",
      " 11  var_7         float64\n",
      " 12  var_8         float64\n",
      " 13  var_9         float64\n",
      " 14  var_10        float64\n",
      " 15  var_11        float64\n",
      " 16  var_12        float64\n",
      " 17  var_13        float64\n",
      " 18  var_14        float64\n",
      " 19  var_15        float64\n",
      " 20  var_16        float64\n",
      " 21  var_17        float64\n",
      " 22  var_18        float64\n",
      " 23  var_19        float64\n",
      " 24  var_20        float64\n",
      " 25  var_21        float64\n",
      " 26  var_22        float64\n",
      " 27  var_23        float64\n",
      " 28  var_24        float64\n",
      " 29  var_25        float64\n",
      " 30  var_26        float64\n",
      " 31  var_27        float64\n",
      " 32  var_28        float64\n",
      " 33  var_29        float64\n",
      " 34  var_30        float64\n",
      " 35  var_31        float64\n",
      " 36  var_32        float64\n",
      " 37  var_33        float64\n",
      " 38  var_34        float64\n",
      " 39  var_35        float64\n",
      " 40  var_36        float64\n",
      " 41  var_37        float64\n",
      " 42  var_38        float64\n",
      " 43  var_39        float64\n",
      " 44  var_40        float64\n",
      " 45  var_41        float64\n",
      " 46  var_42        float64\n",
      " 47  var_43        float64\n",
      " 48  var_44        float64\n",
      " 49  var_45        object \n",
      " 50  var_46        object \n",
      " 51  var_47        object \n",
      " 52  var_48        float64\n",
      " 53  var_49        object \n",
      " 54  var_50        object \n",
      "dtypes: float64(45), int64(2), object(8)\n",
      "memory usage: 841.3+ MB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "fd28dbcd-3280-4a94-b930-88628d71339f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>customer_id</th>\n",
       "      <th>offer_id</th>\n",
       "      <th>var_1</th>\n",
       "      <th>var_2</th>\n",
       "      <th>var_3</th>\n",
       "      <th>var_4</th>\n",
       "      <th>var_5</th>\n",
       "      <th>var_6</th>\n",
       "      <th>var_7</th>\n",
       "      <th>var_8</th>\n",
       "      <th>...</th>\n",
       "      <th>var_36</th>\n",
       "      <th>var_37</th>\n",
       "      <th>var_38</th>\n",
       "      <th>var_39</th>\n",
       "      <th>var_40</th>\n",
       "      <th>var_41</th>\n",
       "      <th>var_42</th>\n",
       "      <th>var_43</th>\n",
       "      <th>var_44</th>\n",
       "      <th>var_48</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>2.004812e+06</td>\n",
       "      <td>2.004812e+06</td>\n",
       "      <td>769235.000000</td>\n",
       "      <td>939953.000000</td>\n",
       "      <td>295718.000000</td>\n",
       "      <td>198259.000000</td>\n",
       "      <td>1.443714e+06</td>\n",
       "      <td>1.674323e+06</td>\n",
       "      <td>1.125559e+06</td>\n",
       "      <td>1.437420e+06</td>\n",
       "      <td>...</td>\n",
       "      <td>27275.000000</td>\n",
       "      <td>1.286100e+06</td>\n",
       "      <td>2.004759e+06</td>\n",
       "      <td>1.857870e+06</td>\n",
       "      <td>1.857870e+06</td>\n",
       "      <td>1.678014e+06</td>\n",
       "      <td>1.846806e+06</td>\n",
       "      <td>1.846806e+06</td>\n",
       "      <td>2004759.0</td>\n",
       "      <td>2.004759e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>1.465379e+06</td>\n",
       "      <td>2.020622e+07</td>\n",
       "      <td>33.973431</td>\n",
       "      <td>32.409650</td>\n",
       "      <td>33.640363</td>\n",
       "      <td>40.631689</td>\n",
       "      <td>3.438814e+01</td>\n",
       "      <td>3.770162e+01</td>\n",
       "      <td>3.613842e+01</td>\n",
       "      <td>3.649525e+01</td>\n",
       "      <td>...</td>\n",
       "      <td>12.835197</td>\n",
       "      <td>2.730998e-01</td>\n",
       "      <td>9.571012e+01</td>\n",
       "      <td>7.011631e+03</td>\n",
       "      <td>9.357645e+04</td>\n",
       "      <td>1.175265e-01</td>\n",
       "      <td>1.181813e-01</td>\n",
       "      <td>3.258467e+03</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.507137e-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>2.594202e+05</td>\n",
       "      <td>9.972241e+07</td>\n",
       "      <td>22.039018</td>\n",
       "      <td>20.558765</td>\n",
       "      <td>24.717924</td>\n",
       "      <td>28.877784</td>\n",
       "      <td>2.151217e+01</td>\n",
       "      <td>1.955954e+01</td>\n",
       "      <td>2.261652e+01</td>\n",
       "      <td>2.120697e+01</td>\n",
       "      <td>...</td>\n",
       "      <td>17.266552</td>\n",
       "      <td>1.658929e-01</td>\n",
       "      <td>5.228714e+01</td>\n",
       "      <td>3.399906e+03</td>\n",
       "      <td>5.284505e+04</td>\n",
       "      <td>9.326043e-02</td>\n",
       "      <td>9.600510e-02</td>\n",
       "      <td>1.062592e+03</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.635065e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1.000125e+06</td>\n",
       "      <td>1.185000e+03</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>...</td>\n",
       "      <td>-33.000000</td>\n",
       "      <td>2.500000e-02</td>\n",
       "      <td>3.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>1.964834e-02</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>1.249353e+06</td>\n",
       "      <td>6.768100e+04</td>\n",
       "      <td>13.000000</td>\n",
       "      <td>19.000000</td>\n",
       "      <td>13.000000</td>\n",
       "      <td>22.000000</td>\n",
       "      <td>1.800000e+01</td>\n",
       "      <td>2.500000e+01</td>\n",
       "      <td>2.000000e+01</td>\n",
       "      <td>2.000000e+01</td>\n",
       "      <td>...</td>\n",
       "      <td>20.000000</td>\n",
       "      <td>2.000000e-01</td>\n",
       "      <td>6.000000e+01</td>\n",
       "      <td>4.482000e+03</td>\n",
       "      <td>4.067200e+04</td>\n",
       "      <td>7.826103e-02</td>\n",
       "      <td>7.333775e-02</td>\n",
       "      <td>2.932000e+03</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>1.467485e+06</td>\n",
       "      <td>9.671300e+04</td>\n",
       "      <td>34.000000</td>\n",
       "      <td>31.000000</td>\n",
       "      <td>31.000000</td>\n",
       "      <td>40.000000</td>\n",
       "      <td>3.400000e+01</td>\n",
       "      <td>3.700000e+01</td>\n",
       "      <td>3.500000e+01</td>\n",
       "      <td>3.600000e+01</td>\n",
       "      <td>...</td>\n",
       "      <td>20.000000</td>\n",
       "      <td>2.000000e-01</td>\n",
       "      <td>9.100000e+01</td>\n",
       "      <td>7.662000e+03</td>\n",
       "      <td>1.086210e+05</td>\n",
       "      <td>9.042495e-02</td>\n",
       "      <td>9.285426e-02</td>\n",
       "      <td>3.458000e+03</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>1.692897e+06</td>\n",
       "      <td>6.358690e+05</td>\n",
       "      <td>46.000000</td>\n",
       "      <td>44.000000</td>\n",
       "      <td>47.000000</td>\n",
       "      <td>64.000000</td>\n",
       "      <td>4.500000e+01</td>\n",
       "      <td>4.700000e+01</td>\n",
       "      <td>4.700000e+01</td>\n",
       "      <td>4.700000e+01</td>\n",
       "      <td>...</td>\n",
       "      <td>23.000000</td>\n",
       "      <td>3.000000e-01</td>\n",
       "      <td>1.220000e+02</td>\n",
       "      <td>9.079000e+03</td>\n",
       "      <td>1.432130e+05</td>\n",
       "      <td>1.147157e-01</td>\n",
       "      <td>1.287612e-01</td>\n",
       "      <td>3.957000e+03</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1.910509e+06</td>\n",
       "      <td>8.766658e+08</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>1.000000e+02</td>\n",
       "      <td>1.000000e+02</td>\n",
       "      <td>1.000000e+02</td>\n",
       "      <td>1.000000e+02</td>\n",
       "      <td>...</td>\n",
       "      <td>33.000000</td>\n",
       "      <td>2.000000e+00</td>\n",
       "      <td>1.357000e+03</td>\n",
       "      <td>3.510200e+04</td>\n",
       "      <td>1.763500e+05</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>5.704000e+03</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.000000e+00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows Ã— 47 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        customer_id      offer_id          var_1          var_2  \\\n",
       "count  2.004812e+06  2.004812e+06  769235.000000  939953.000000   \n",
       "mean   1.465379e+06  2.020622e+07      33.973431      32.409650   \n",
       "std    2.594202e+05  9.972241e+07      22.039018      20.558765   \n",
       "min    1.000125e+06  1.185000e+03       1.000000       1.000000   \n",
       "25%    1.249353e+06  6.768100e+04      13.000000      19.000000   \n",
       "50%    1.467485e+06  9.671300e+04      34.000000      31.000000   \n",
       "75%    1.692897e+06  6.358690e+05      46.000000      44.000000   \n",
       "max    1.910509e+06  8.766658e+08     100.000000     100.000000   \n",
       "\n",
       "               var_3          var_4         var_5         var_6         var_7  \\\n",
       "count  295718.000000  198259.000000  1.443714e+06  1.674323e+06  1.125559e+06   \n",
       "mean       33.640363      40.631689  3.438814e+01  3.770162e+01  3.613842e+01   \n",
       "std        24.717924      28.877784  2.151217e+01  1.955954e+01  2.261652e+01   \n",
       "min         1.000000       1.000000  1.000000e+00  1.000000e+00  1.000000e+00   \n",
       "25%        13.000000      22.000000  1.800000e+01  2.500000e+01  2.000000e+01   \n",
       "50%        31.000000      40.000000  3.400000e+01  3.700000e+01  3.500000e+01   \n",
       "75%        47.000000      64.000000  4.500000e+01  4.700000e+01  4.700000e+01   \n",
       "max       100.000000     100.000000  1.000000e+02  1.000000e+02  1.000000e+02   \n",
       "\n",
       "              var_8  ...        var_36        var_37        var_38  \\\n",
       "count  1.437420e+06  ...  27275.000000  1.286100e+06  2.004759e+06   \n",
       "mean   3.649525e+01  ...     12.835197  2.730998e-01  9.571012e+01   \n",
       "std    2.120697e+01  ...     17.266552  1.658929e-01  5.228714e+01   \n",
       "min    1.000000e+00  ...    -33.000000  2.500000e-02  3.000000e+00   \n",
       "25%    2.000000e+01  ...     20.000000  2.000000e-01  6.000000e+01   \n",
       "50%    3.600000e+01  ...     20.000000  2.000000e-01  9.100000e+01   \n",
       "75%    4.700000e+01  ...     23.000000  3.000000e-01  1.220000e+02   \n",
       "max    1.000000e+02  ...     33.000000  2.000000e+00  1.357000e+03   \n",
       "\n",
       "             var_39        var_40        var_41        var_42        var_43  \\\n",
       "count  1.857870e+06  1.857870e+06  1.678014e+06  1.846806e+06  1.846806e+06   \n",
       "mean   7.011631e+03  9.357645e+04  1.175265e-01  1.181813e-01  3.258467e+03   \n",
       "std    3.399906e+03  5.284505e+04  9.326043e-02  9.600510e-02  1.062592e+03   \n",
       "min    0.000000e+00  1.000000e+00  0.000000e+00  1.964834e-02  1.000000e+00   \n",
       "25%    4.482000e+03  4.067200e+04  7.826103e-02  7.333775e-02  2.932000e+03   \n",
       "50%    7.662000e+03  1.086210e+05  9.042495e-02  9.285426e-02  3.458000e+03   \n",
       "75%    9.079000e+03  1.432130e+05  1.147157e-01  1.287612e-01  3.957000e+03   \n",
       "max    3.510200e+04  1.763500e+05  1.000000e+00  1.000000e+00  5.704000e+03   \n",
       "\n",
       "          var_44        var_48  \n",
       "count  2004759.0  2.004759e+06  \n",
       "mean         0.0  7.507137e-02  \n",
       "std          0.0  2.635065e-01  \n",
       "min          0.0  0.000000e+00  \n",
       "25%          0.0  0.000000e+00  \n",
       "50%          0.0  0.000000e+00  \n",
       "75%          0.0  0.000000e+00  \n",
       "max          0.0  1.000000e+00  \n",
       "\n",
       "[8 rows x 47 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c586806e-96e3-4563-929a-35d88ff4feb6",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "time data \"09 Nov 2023 08:37\" doesn't match format \"%Y-%m-%d %H:%M:%S.%f\", at position 7. You might want to try:\n    - passing `format` if your strings have a consistent format;\n    - passing `format='ISO8601'` if your strings are all ISO8601 but not necessarily in exactly the same format;\n    - passing `format='mixed'`, and the format will be inferred for each element individually. You might want to use `dayfirst` alongside this.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[12], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mevent_ts\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mto_datetime(df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mevent_ts\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[0;32m      2\u001b[0m df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mevent_dt\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mto_datetime(df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mevent_dt\u001b[39m\u001b[38;5;124m'\u001b[39m])\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1067\u001b[0m, in \u001b[0;36mto_datetime\u001b[1;34m(arg, errors, dayfirst, yearfirst, utc, format, exact, unit, infer_datetime_format, origin, cache)\u001b[0m\n\u001b[0;32m   1065\u001b[0m         result \u001b[38;5;241m=\u001b[39m arg\u001b[38;5;241m.\u001b[39mmap(cache_array)\n\u001b[0;32m   1066\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1067\u001b[0m         values \u001b[38;5;241m=\u001b[39m convert_listlike(arg\u001b[38;5;241m.\u001b[39m_values, \u001b[38;5;28mformat\u001b[39m)\n\u001b[0;32m   1068\u001b[0m         result \u001b[38;5;241m=\u001b[39m arg\u001b[38;5;241m.\u001b[39m_constructor(values, index\u001b[38;5;241m=\u001b[39marg\u001b[38;5;241m.\u001b[39mindex, name\u001b[38;5;241m=\u001b[39marg\u001b[38;5;241m.\u001b[39mname)\n\u001b[0;32m   1069\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(arg, (ABCDataFrame, abc\u001b[38;5;241m.\u001b[39mMutableMapping)):\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\core\\tools\\datetimes.py:433\u001b[0m, in \u001b[0;36m_convert_listlike_datetimes\u001b[1;34m(arg, format, name, utc, unit, errors, dayfirst, yearfirst, exact)\u001b[0m\n\u001b[0;32m    431\u001b[0m \u001b[38;5;66;03m# `format` could be inferred, or user didn't ask for mixed-format parsing.\u001b[39;00m\n\u001b[0;32m    432\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mformat\u001b[39m \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mformat\u001b[39m \u001b[38;5;241m!=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmixed\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m--> 433\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m _array_strptime_with_fallback(arg, name, utc, \u001b[38;5;28mformat\u001b[39m, exact, errors)\n\u001b[0;32m    435\u001b[0m result, tz_parsed \u001b[38;5;241m=\u001b[39m objects_to_datetime64(\n\u001b[0;32m    436\u001b[0m     arg,\n\u001b[0;32m    437\u001b[0m     dayfirst\u001b[38;5;241m=\u001b[39mdayfirst,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    441\u001b[0m     allow_object\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[0;32m    442\u001b[0m )\n\u001b[0;32m    444\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m tz_parsed \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    445\u001b[0m     \u001b[38;5;66;03m# We can take a shortcut since the datetime64 numpy array\u001b[39;00m\n\u001b[0;32m    446\u001b[0m     \u001b[38;5;66;03m# is in UTC\u001b[39;00m\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\core\\tools\\datetimes.py:467\u001b[0m, in \u001b[0;36m_array_strptime_with_fallback\u001b[1;34m(arg, name, utc, fmt, exact, errors)\u001b[0m\n\u001b[0;32m    456\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_array_strptime_with_fallback\u001b[39m(\n\u001b[0;32m    457\u001b[0m     arg,\n\u001b[0;32m    458\u001b[0m     name,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    462\u001b[0m     errors: \u001b[38;5;28mstr\u001b[39m,\n\u001b[0;32m    463\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Index:\n\u001b[0;32m    464\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    465\u001b[0m \u001b[38;5;124;03m    Call array_strptime, with fallback behavior depending on 'errors'.\u001b[39;00m\n\u001b[0;32m    466\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 467\u001b[0m     result, tz_out \u001b[38;5;241m=\u001b[39m array_strptime(arg, fmt, exact\u001b[38;5;241m=\u001b[39mexact, errors\u001b[38;5;241m=\u001b[39merrors, utc\u001b[38;5;241m=\u001b[39mutc)\n\u001b[0;32m    468\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m tz_out \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    469\u001b[0m         unit \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mdatetime_data(result\u001b[38;5;241m.\u001b[39mdtype)[\u001b[38;5;241m0\u001b[39m]\n",
      "File \u001b[1;32mstrptime.pyx:501\u001b[0m, in \u001b[0;36mpandas._libs.tslibs.strptime.array_strptime\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mstrptime.pyx:451\u001b[0m, in \u001b[0;36mpandas._libs.tslibs.strptime.array_strptime\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mstrptime.pyx:583\u001b[0m, in \u001b[0;36mpandas._libs.tslibs.strptime._parse_with_format\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: time data \"09 Nov 2023 08:37\" doesn't match format \"%Y-%m-%d %H:%M:%S.%f\", at position 7. You might want to try:\n    - passing `format` if your strings have a consistent format;\n    - passing `format='ISO8601'` if your strings are all ISO8601 but not necessarily in exactly the same format;\n    - passing `format='mixed'`, and the format will be inferred for each element individually. You might want to use `dayfirst` alongside this."
     ]
    }
   ],
   "source": [
    "df['event_ts'] = pd.to_datetime(df['event_ts'])\n",
    "df['event_dt'] = pd.to_datetime(df['event_dt'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "53da116c-cde8-4dca-9a70-97e180e15fa5",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['event_ts'] = pd.to_datetime(df['event_ts'], format='mixed')\n",
    "df['event_dt'] = pd.to_datetime(df['event_dt'], format='mixed')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "992b3c39-91db-4100-a937-8c10c636a7bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Date columns converted successfully!\n"
     ]
    }
   ],
   "source": [
    "print(\"Date columns converted successfully!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "8bd519cf-5c2a-4fb8-a9fa-e00a47116708",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 2004812 entries, 0 to 2004811\n",
      "Data columns (total 55 columns):\n",
      " #   Column        Dtype         \n",
      "---  ------        -----         \n",
      " 0   customer_id   int64         \n",
      " 1   offer_id      int64         \n",
      " 2   event_ts      datetime64[ns]\n",
      " 3   event_dt      datetime64[ns]\n",
      " 4   offer_action  object        \n",
      " 5   var_1         float64       \n",
      " 6   var_2         float64       \n",
      " 7   var_3         float64       \n",
      " 8   var_4         float64       \n",
      " 9   var_5         float64       \n",
      " 10  var_6         float64       \n",
      " 11  var_7         float64       \n",
      " 12  var_8         float64       \n",
      " 13  var_9         float64       \n",
      " 14  var_10        float64       \n",
      " 15  var_11        float64       \n",
      " 16  var_12        float64       \n",
      " 17  var_13        float64       \n",
      " 18  var_14        float64       \n",
      " 19  var_15        float64       \n",
      " 20  var_16        float64       \n",
      " 21  var_17        float64       \n",
      " 22  var_18        float64       \n",
      " 23  var_19        float64       \n",
      " 24  var_20        float64       \n",
      " 25  var_21        float64       \n",
      " 26  var_22        float64       \n",
      " 27  var_23        float64       \n",
      " 28  var_24        float64       \n",
      " 29  var_25        float64       \n",
      " 30  var_26        float64       \n",
      " 31  var_27        float64       \n",
      " 32  var_28        float64       \n",
      " 33  var_29        float64       \n",
      " 34  var_30        float64       \n",
      " 35  var_31        float64       \n",
      " 36  var_32        float64       \n",
      " 37  var_33        float64       \n",
      " 38  var_34        float64       \n",
      " 39  var_35        float64       \n",
      " 40  var_36        float64       \n",
      " 41  var_37        float64       \n",
      " 42  var_38        float64       \n",
      " 43  var_39        float64       \n",
      " 44  var_40        float64       \n",
      " 45  var_41        float64       \n",
      " 46  var_42        float64       \n",
      " 47  var_43        float64       \n",
      " 48  var_44        float64       \n",
      " 49  var_45        object        \n",
      " 50  var_46        object        \n",
      " 51  var_47        object        \n",
      " 52  var_48        float64       \n",
      " 53  var_49        object        \n",
      " 54  var_50        object        \n",
      "dtypes: datetime64[ns](2), float64(45), int64(2), object(6)\n",
      "memory usage: 841.3+ MB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "0d068378-28e0-4c54-a697-ff760aa9fcca",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sqlite3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "bb6d51fd-5b72-4fb6-b4d8-670f5bdbc197",
   "metadata": {},
   "outputs": [],
   "source": [
    "conn = sqlite3.connect('amex_challenge.db')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "f8570669-e684-4d94-800b-a082f0e55f6f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Database connection established successfully.\n"
     ]
    }
   ],
   "source": [
    "print(\"Database connection established successfully.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "66ec759f-6190-4e08-915e-aedd38f345f4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2004812"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.to_sql('clickstream', conn, if_exists='replace', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "d782a79f-22b8-41a9-87c4-b8b2e15bdd87",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DataFrame has been successfully written to the SQL table 'clickstream'.\n"
     ]
    }
   ],
   "source": [
    "print(\"DataFrame has been successfully written to the SQL table 'clickstream'.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "c657f936-541f-446f-82ae-b39325cd562f",
   "metadata": {},
   "outputs": [],
   "source": [
    "sql_query = \"SELECT * FROM clickstream LIMIT 5;\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "68d25cfe-0a70-4f8e-8a35-0fdbadefd57d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>customer_id</th>\n",
       "      <th>offer_id</th>\n",
       "      <th>event_ts</th>\n",
       "      <th>event_dt</th>\n",
       "      <th>offer_action</th>\n",
       "      <th>var_1</th>\n",
       "      <th>var_2</th>\n",
       "      <th>var_3</th>\n",
       "      <th>var_4</th>\n",
       "      <th>var_5</th>\n",
       "      <th>...</th>\n",
       "      <th>var_41</th>\n",
       "      <th>var_42</th>\n",
       "      <th>var_43</th>\n",
       "      <th>var_44</th>\n",
       "      <th>var_45</th>\n",
       "      <th>var_46</th>\n",
       "      <th>var_47</th>\n",
       "      <th>var_48</th>\n",
       "      <th>var_49</th>\n",
       "      <th>var_50</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1010494</td>\n",
       "      <td>601711</td>\n",
       "      <td>2023-11-01 10:25:21.000904</td>\n",
       "      <td>2023-11-01 00:00:00</td>\n",
       "      <td>1</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>...</td>\n",
       "      <td>0.089583</td>\n",
       "      <td>0.083204</td>\n",
       "      <td>2151.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>True</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1010494</td>\n",
       "      <td>33452</td>\n",
       "      <td>2023-11-09 08:37:35.165000</td>\n",
       "      <td>2023-11-09 00:00:00</td>\n",
       "      <td>0</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>...</td>\n",
       "      <td>0.111752</td>\n",
       "      <td>0.181776</td>\n",
       "      <td>1668.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1010494</td>\n",
       "      <td>88456737</td>\n",
       "      <td>2023-11-01 10:15:55.000489</td>\n",
       "      <td>2023-11-01 00:00:00</td>\n",
       "      <td>1</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>...</td>\n",
       "      <td>0.088514</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1010494</td>\n",
       "      <td>390981</td>\n",
       "      <td>2023-11-01 10:27:27.000313</td>\n",
       "      <td>2023-11-01 00:00:00</td>\n",
       "      <td>1</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>...</td>\n",
       "      <td>0.086931</td>\n",
       "      <td>0.059246</td>\n",
       "      <td>3678.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>False</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1010494</td>\n",
       "      <td>7114</td>\n",
       "      <td>2023-11-09 08:37:38.553000</td>\n",
       "      <td>2023-11-09 00:00:00</td>\n",
       "      <td>0</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>...</td>\n",
       "      <td>0.089497</td>\n",
       "      <td>0.124221</td>\n",
       "      <td>3619.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>False</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 55 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   customer_id  offer_id                    event_ts             event_dt  \\\n",
       "0      1010494    601711  2023-11-01 10:25:21.000904  2023-11-01 00:00:00   \n",
       "1      1010494     33452  2023-11-09 08:37:35.165000  2023-11-09 00:00:00   \n",
       "2      1010494  88456737  2023-11-01 10:15:55.000489  2023-11-01 00:00:00   \n",
       "3      1010494    390981  2023-11-01 10:27:27.000313  2023-11-01 00:00:00   \n",
       "4      1010494      7114  2023-11-09 08:37:38.553000  2023-11-09 00:00:00   \n",
       "\n",
       "  offer_action var_1 var_2 var_3 var_4 var_5  ...    var_41    var_42  var_43  \\\n",
       "0            1  None  None  None  None  None  ...  0.089583  0.083204  2151.0   \n",
       "1            0  None  None  None  None  None  ...  0.111752  0.181776  1668.0   \n",
       "2            1  None  None  None  None  None  ...  0.088514       NaN     NaN   \n",
       "3            1  None  None  None  None  None  ...  0.086931  0.059246  3678.0   \n",
       "4            0  None  None  None  None  None  ...  0.089497  0.124221  3619.0   \n",
       "\n",
       "  var_44 var_45 var_46 var_47 var_48 var_49 var_50  \n",
       "0    0.0    0.0    0.0    0.0    0.0   True    0.0  \n",
       "1    0.0    0.0    0.0    0.0    0.0    1.0    0.0  \n",
       "2    0.0    0.0    0.0    0.0    0.0    1.0    0.0  \n",
       "3    0.0  False    0.0    0.0    0.0    1.0    0.0  \n",
       "4    0.0    0.0    0.0  False    0.0    1.0    0.0  \n",
       "\n",
       "[5 rows x 55 columns]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.read_sql_query(sql_query, conn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "757b6ff8-5f08-43b5-9e8c-437d9f775070",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final clickstream table created with 'is_active_user' flag. Ready to answer Question 1.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "q1_preprocessing_query = \"\"\"\n",
    "/*\n",
    "A CTE is like a temporary table. This one calculates the number of days since a user's last visit.\n",
    "The LAG() function is a powerful tool that can 'look back' at the previous row for the same customer.\n",
    "*/\n",
    "WITH ActivityStatus AS (\n",
    "    SELECT\n",
    "        rowid, -- SQLite's unique identifier for each row\n",
    "        customer_id,\n",
    "        event_ts,\n",
    "        JULIANDAY(event_ts) - JULIANDAY(LAG(event_ts, 1, '1900-01-01') OVER (PARTITION BY customer_id ORDER BY event_ts)) AS days_since_last_visit\n",
    "    FROM\n",
    "        clickstream\n",
    ")\n",
    "-- This final SELECT joins the original data with our calculation to create the 'is_active_user' flag.\n",
    "SELECT\n",
    "    c.*,\n",
    "    CASE \n",
    "        WHEN a.days_since_last_visit <= 30 THEN 1 \n",
    "        ELSE 0 \n",
    "    END AS is_active_user\n",
    "FROM\n",
    "    clickstream c\n",
    "JOIN\n",
    "    ActivityStatus a ON c.rowid = a.rowid;\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "df_final = pd.read_sql_query(q1_preprocessing_query, conn)\n",
    "\n",
    "df_final.to_sql('clickstream_final', conn, if_exists='replace', index=False)\n",
    "\n",
    "print(\"Final clickstream table created with 'is_active_user' flag. Ready to answer Question 1.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "b884ec1e-05ee-4a21-ad23-f6beb50f8a57",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Inspecting columns to find 'offer_category' --- \n",
      "\n",
      "--- Unique values in column: offer_action ---\n",
      "['1' '0' 'False' 'True']\n",
      "\n",
      "\n",
      "--- Unique values in column: var_45 ---\n",
      "['0.0' 'False' '1.0' 'True']\n",
      "\n",
      "\n",
      "--- Unique values in column: var_46 ---\n",
      "['0.0' 'False' '1.0' 'True']\n",
      "\n",
      "\n",
      "--- Unique values in column: var_47 ---\n",
      "['0.0' 'False']\n",
      "\n",
      "\n",
      "--- Unique values in column: var_49 ---\n",
      "['True' '1.0' '0.0' 'False']\n",
      "\n",
      "\n",
      "--- Unique values in column: var_50 ---\n",
      "['0.0' 'False' 'True' '1.0']\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Let's inspect all the columns that contain non-numerical data\n",
    "object_columns = df.select_dtypes(include='object').columns\n",
    "\n",
    "print(\"--- Inspecting columns to find 'offer_category' --- \\n\")\n",
    "\n",
    "for col in object_columns:\n",
    "    # We check for nulls first, then get unique values\n",
    "    if df[col].isnull().all():\n",
    "        print(f\"Column '{col}' is all nulls.\\n\")\n",
    "    else:\n",
    "        print(f\"--- Unique values in column: {col} ---\")\n",
    "        # Show up to the first 10 unique values to keep the output clean\n",
    "        print(df[col].dropna().unique()[:10])\n",
    "        print(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "37021db1-1e5a-40c6-ac4f-2a06aef9e66a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of unique values in each 'var' column (showing top candidates):\n",
      "var_22     1\n",
      "var_31     1\n",
      "var_44     1\n",
      "var_48     2\n",
      "var_16     2\n",
      "var_47     2\n",
      "var_49     4\n",
      "var_50     4\n",
      "var_46     4\n",
      "var_45     4\n",
      "var_14    12\n",
      "var_36    14\n",
      "var_33    15\n",
      "var_15    15\n",
      "var_35    22\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "\n",
    "var_columns = [col for col in df.columns if 'var_' in col]\n",
    "\n",
    "unique_counts = df[var_columns].nunique()\n",
    "\n",
    "print(\"Number of unique values in each 'var' column (showing top candidates):\")\n",
    "print(unique_counts.sort_values().head(15))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "725c6c5b-99fa-46ee-afdc-852c590c89fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Click-Through Rates by Category and User Activity:\n",
      "   is_active_user offer_category_encoded       ctr\n",
      "0               0                   None  0.000000\n",
      "1               1                   None  0.057692\n",
      "2               0                    0.0  0.163192\n",
      "3               1                    0.0  0.052981\n",
      "4               0                    1.0  0.134974\n",
      "5               1                    1.0  0.053333\n",
      "6               0                  False  0.108861\n",
      "7               1                  False  0.051871\n",
      "8               0                   True  0.153299\n",
      "9               1                   True  0.053126\n",
      "\n",
      "--- Analysis ---\n",
      "To find your answer, compare the 'ctr' for the same 'offer_category_encoded' between is_active_user=0 and is_active_user=1.\n",
      "If you see a category where the CTR for active users (1) is noticeably higher than for inactive users (0), the statement is TRUE.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "q1_1_corrected_query = \"\"\"\n",
    "SELECT\n",
    "    is_active_user,\n",
    "    var_49 AS offer_category_encoded,\n",
    "    SUM(CASE WHEN offer_action = '1' THEN 1.0 ELSE 0.0 END) / COUNT(*) AS ctr\n",
    "FROM\n",
    "    clickstream_final\n",
    "GROUP BY\n",
    "    is_active_user, offer_category_encoded\n",
    "ORDER BY\n",
    "    offer_category_encoded, is_active_user;\n",
    "\"\"\"\n",
    "result_1_1 = pd.read_sql_query(q1_1_corrected_query, conn)\n",
    "print(\"Click-Through Rates by Category and User Activity:\")\n",
    "print(result_1_1)\n",
    "\n",
    "print(\"\\n--- Analysis ---\")\n",
    "print(\"To find your answer, compare the 'ctr' for the same 'offer_category_encoded' between is_active_user=0 and is_active_user=1.\")\n",
    "print(\"If you see a category where the CTR for active users (1) is noticeably higher than for inactive users (0), the statement is TRUE.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "815f2158-8afb-457a-afea-bf1eadaa4d77",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   is_active_user  avg_discount_saved\n",
      "0               0         2780.684486\n",
      "1               1         3003.129487\n",
      "\n",
      "Answer 1.2 is: TRUE\n"
     ]
    }
   ],
   "source": [
    "q1_2_corrected_query = \"\"\"\n",
    "SELECT\n",
    "    is_active_user,\n",
    "    AVG(var_43) AS avg_discount_saved\n",
    "FROM\n",
    "    clickstream_final\n",
    "WHERE\n",
    "    offer_action = '1' -- Only for offers that were clicked\n",
    "GROUP BY\n",
    "    is_active_user;\n",
    "\"\"\"\n",
    "result_1_2 = pd.read_sql_query(q1_2_corrected_query, conn)\n",
    "print(result_1_2)\n",
    "\n",
    "# Logic to determine the answer\n",
    "if result_1_2.loc[1, 'avg_discount_saved'] > result_1_2.loc[0, 'avg_discount_saved']:\n",
    "    print(\"\\nAnswer 1.2 is: TRUE\")\n",
    "else:\n",
    "    print(\"\\nAnswer 1.2 is: FALSE\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "d35ae526-718e-4c2e-bef4-057b307b1895",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Answer 1.3 is: 8867\n"
     ]
    }
   ],
   "source": [
    "# We will use the encoded category '1.0' to represent 'Airline' for this calculation.\n",
    "q1_3_corrected_query = \"\"\"\n",
    "SELECT\n",
    "    COUNT(DISTINCT customer_id) AS customer_count\n",
    "FROM\n",
    "    clickstream_final\n",
    "WHERE\n",
    "    is_active_user = 1\n",
    "    AND var_49 = '1.0'\n",
    "    AND offer_action = '1';\n",
    "\"\"\"\n",
    "result_1_3 = pd.read_sql_query(q1_3_corrected_query, conn)\n",
    "\n",
    "print(f\"\\nAnswer 1.3 is: {result_1_3.loc[0, 'customer_count']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "1dfc771e-6942-427f-8f7d-a8472fdbd08b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The 50th Percentile (Median) for 'var_42' is: 0.0928542576613046\n",
      "\n",
      "Difference in Conversion Rates (High - Low Discount):\n",
      "  offer_category_encoded  ctr_difference\n",
      "0                   None             NaN\n",
      "1                    0.0        0.035716\n",
      "2                    1.0        0.034736\n",
      "3                  False        0.035702\n",
      "4                   True        0.034943\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# We exclude offers with no discount value, as per the note in the problem.\n",
    "df_for_median = pd.read_sql_query(\"SELECT var_42 FROM clickstream_final WHERE var_42 > 0;\", conn)\n",
    "median_value = df_for_median['var_42'].median()\n",
    "\n",
    "print(f\"The 50th Percentile (Median) for 'var_42' is: {median_value}\\n\")\n",
    "\n",
    "\n",
    "q2_query = f\"\"\"\n",
    "/* This CTE calculates the conversion rate for High and Low tier offers separately */\n",
    "WITH OfferTiers AS (\n",
    "    SELECT\n",
    "        var_49 AS offer_category_encoded,\n",
    "        CASE WHEN var_42 >= {median_value} THEN 'High' ELSE 'Low' END as discount_tier,\n",
    "        offer_action\n",
    "    FROM\n",
    "        clickstream_final\n",
    "    WHERE\n",
    "        var_42 > 0 -- Exclude offers with no discount value\n",
    "),\n",
    "/* This CTE calculates the CTR for each group */\n",
    "CtrByTier AS (\n",
    "    SELECT\n",
    "        offer_category_encoded,\n",
    "        discount_tier,\n",
    "        SUM(CASE WHEN offer_action = '1' THEN 1.0 ELSE 0.0 END) / COUNT(*) AS ctr\n",
    "    FROM\n",
    "        OfferTiers\n",
    "    GROUP BY\n",
    "        offer_category_encoded, discount_tier\n",
    ")\n",
    "/* Final query pivots the data to calculate the difference */\n",
    "SELECT\n",
    "    offer_category_encoded,\n",
    "    MAX(CASE WHEN discount_tier = 'High' THEN ctr END) - MAX(CASE WHEN discount_tier = 'Low' THEN ctr END) AS ctr_difference\n",
    "FROM\n",
    "    CtrByTier\n",
    "GROUP BY\n",
    "    offer_category_encoded;\n",
    "\"\"\"\n",
    "\n",
    "result_2 = pd.read_sql_query(q2_query, conn)\n",
    "\n",
    "print(\"Difference in Conversion Rates (High - Low Discount):\")\n",
    "print(result_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "b3c05d7c-b140-4bb9-a0bb-18cf110d64d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Customer spending segments created successfully.\n",
      "\n",
      "--- Answer 3.1: Average Rate of OFFERS OFFERED ---\n",
      "   spend_tier  avg_offered_rate\n",
      "0           1          0.114204\n",
      "1           2          0.116447\n",
      "2           3          0.120047\n",
      "\n",
      "\n",
      "--- Answer 3.2: Average Rate of OFFERS PARTICIPATED IN ---\n",
      "   spend_tier  avg_participated_rate\n",
      "0           1               0.127139\n",
      "1           2               0.134591\n",
      "2           3               0.134119\n",
      "\n",
      "\n",
      "--- Answer 3.3: Best Performing Segment ---\n",
      "The best performing segment is: MEDIUM\n"
     ]
    }
   ],
   "source": [
    "# Step 1: Create a new table in our database with customer spending segments\n",
    "q3_segment_query = \"\"\"\n",
    "-- First, create a temporary table of each customer's max spend (using our hypothesized spend column var_36)\n",
    "WITH CustomerMaxSpend AS (\n",
    "    SELECT\n",
    "        customer_id,\n",
    "        MAX(var_36) as max_spend\n",
    "    FROM\n",
    "        clickstream_final\n",
    "    GROUP BY\n",
    "        customer_id\n",
    ")\n",
    "-- Now, assign each customer to a tier (1=Low, 2=Medium, 3=High)\n",
    "SELECT\n",
    "    customer_id,\n",
    "    NTILE(3) OVER (ORDER BY max_spend) as spend_tier\n",
    "FROM\n",
    "    CustomerMaxSpend;\n",
    "\"\"\"\n",
    "df_segments = pd.read_sql_query(q3_segment_query, conn)\n",
    "# Save these segments to a new table for easy access\n",
    "df_segments.to_sql('customer_segments', conn, if_exists='replace', index=False)\n",
    "print(\"Customer spending segments created successfully.\\n\")\n",
    "\n",
    "\n",
    "# Step 2: Calculate the AVERAGE REWARD RATE OF OFFERS OFFERED to each category (Answer 3.1)\n",
    "q3_offered_rate_query = \"\"\"\n",
    "SELECT\n",
    "    s.spend_tier,\n",
    "    AVG(c.var_41) as avg_offered_rate -- using hypothesized reward rate column var_41\n",
    "FROM\n",
    "    clickstream_final c\n",
    "JOIN\n",
    "    customer_segments s ON c.customer_id = s.customer_id\n",
    "WHERE\n",
    "    c.var_41 IS NOT NULL\n",
    "GROUP BY\n",
    "    s.spend_tier;\n",
    "\"\"\"\n",
    "df_offered = pd.read_sql_query(q3_offered_rate_query, conn)\n",
    "print(\"--- Answer 3.1: Average Rate of OFFERS OFFERED ---\")\n",
    "print(df_offered)\n",
    "print(\"\\n\")\n",
    "\n",
    "\n",
    "# Step 3: Calculate the AVERAGE REWARD RATE OF OFFERS PARTICIPATED IN (Answer 3.2)\n",
    "q3_participated_rate_query = \"\"\"\n",
    "SELECT\n",
    "    s.spend_tier,\n",
    "    AVG(c.var_41) as avg_participated_rate\n",
    "FROM\n",
    "    clickstream_final c\n",
    "JOIN\n",
    "    customer_segments s ON c.customer_id = s.customer_id\n",
    "WHERE\n",
    "    c.offer_action = '1' -- The only difference is we filter for clicked offers\n",
    "    AND c.var_41 IS NOT NULL\n",
    "GROUP BY\n",
    "    s.spend_tier;\n",
    "\"\"\"\n",
    "df_participated = pd.read_sql_query(q3_participated_rate_query, conn)\n",
    "print(\"--- Answer 3.2: Average Rate of OFFERS PARTICIPATED IN ---\")\n",
    "print(df_participated)\n",
    "print(\"\\n\")\n",
    "\n",
    "\n",
    "# Step 4: Determine the BEST PERFORMING SEGMENT (Answer 3.3)\n",
    "# We merge the two results and calculate a performance ratio\n",
    "df_performance = pd.merge(df_offered, df_participated, on='spend_tier')\n",
    "df_performance['performance_ratio'] = df_performance['avg_participated_rate'] / df_performance['avg_offered_rate']\n",
    "\n",
    "# Find the tier with the highest ratio\n",
    "best_segment_tier = df_performance.loc[df_performance['performance_ratio'].idxmax()]\n",
    "tier_map = {1: 'LOW', 2: 'MEDIUM', 3: 'HIGH'}\n",
    "best_segment_name = tier_map[best_segment_tier['spend_tier']]\n",
    "\n",
    "print(\"--- Answer 3.3: Best Performing Segment ---\")\n",
    "print(f\"The best performing segment is: {best_segment_name}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "d97b074f-fe33-4c48-99b2-a556043e9bd2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The average offer presentation count is: 2421.2705314009663\n",
      "\n",
      "--- Answer 4.1: Top 10 Offer ID to Offer Category Mappings ---\n",
      "   offer_id offer_category_encoded  conversion_rate\n",
      "0      2788                    1.0         0.243088\n",
      "1     60448                    1.0         0.194751\n",
      "2     25852                    0.0         0.176562\n",
      "3    281783                    1.0         0.145514\n",
      "4      1185                    0.0         0.141065\n",
      "5    159555                    1.0         0.129280\n",
      "6    689367                    1.0         0.125460\n",
      "7    331980                    1.0         0.124890\n",
      "8    633765                    1.0         0.124448\n",
      "9    498907                    0.0         0.122201\n",
      "\n",
      "\n",
      "--- Answer 4.2: Average 3-Month Spend of Customers ---\n",
      "12.614209673686647\n",
      "\n",
      "--- Answer 4.3: Recent Conversion Rate for Top 10 Offers ---\n",
      "   offer_id  recent_conversion_rate\n",
      "0      1185                0.188679\n",
      "1      2788                0.319006\n",
      "2     25852                0.219003\n",
      "3     60448                0.253623\n",
      "4    159555                0.184534\n",
      "5    281783                0.173222\n",
      "6    331980                0.148816\n",
      "7    498907                0.138073\n",
      "8    633765                0.164625\n",
      "9    689367                0.157512\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Step 1: Calculate the average offer presentation count (our threshold)\n",
    "avg_presentations_query = \"SELECT COUNT(*) * 1.0 / COUNT(DISTINCT offer_id) FROM clickstream_final;\"\n",
    "avg_presentations = pd.read_sql_query(avg_presentations_query, conn).iloc[0, 0]\n",
    "print(f\"The average offer presentation count is: {avg_presentations}\\n\")\n",
    "\n",
    "# Step 2: Find the Top 10 Offers by Conversion Rate (Answer 4.1)\n",
    "# Using our hypotheses: var_49 is offer category\n",
    "top_10_offers_query = f\"\"\"\n",
    "WITH OfferPerformance AS (\n",
    "    SELECT\n",
    "        offer_id,\n",
    "        var_49 AS offer_category_encoded,\n",
    "        COUNT(*) as times_viewed,\n",
    "        SUM(CASE WHEN offer_action = '1' THEN 1.0 ELSE 0.0 END) as times_clicked\n",
    "    FROM clickstream_final\n",
    "    GROUP BY offer_id, offer_category_encoded\n",
    ")\n",
    "SELECT\n",
    "    offer_id,\n",
    "    offer_category_encoded,\n",
    "    times_clicked / times_viewed AS conversion_rate\n",
    "FROM\n",
    "    OfferPerformance\n",
    "WHERE\n",
    "    times_viewed > {avg_presentations} -- Apply the threshold\n",
    "ORDER BY\n",
    "    conversion_rate DESC\n",
    "LIMIT 10;\n",
    "\"\"\"\n",
    "df_top_10 = pd.read_sql_query(top_10_offers_query, conn)\n",
    "print(\"--- Answer 4.1: Top 10 Offer ID to Offer Category Mappings ---\")\n",
    "print(df_top_10)\n",
    "print(\"\\n\")\n",
    "\n",
    "# Create a list of the top 10 offer IDs to use in the next queries\n",
    "top_10_offer_ids = df_top_10['offer_id'].tolist()\n",
    "# We need to format this list for use in an SQL \"IN\" clause\n",
    "top_10_ids_str = ', '.join(map(str, top_10_offer_ids))\n",
    "\n",
    "\n",
    "# Step 3: Find the average 3-month spend of customers for these offers (Answer 4.2)\n",
    "# Using our hypothesis: var_36 is spend amount. Date is as of Nov 7, 2023.\n",
    "avg_spend_query = f\"\"\"\n",
    "SELECT\n",
    "    AVG(var_36) as avg_3_month_spend\n",
    "FROM\n",
    "    clickstream_final\n",
    "WHERE\n",
    "    customer_id IN (\n",
    "        SELECT DISTINCT customer_id\n",
    "        FROM clickstream_final\n",
    "        WHERE offer_id IN ({top_10_ids_str}) AND offer_action = '1'\n",
    "    )\n",
    "    AND event_dt BETWEEN '2023-08-07' AND '2023-11-07'; -- Last 3 months from Nov 7\n",
    "\"\"\"\n",
    "avg_spend = pd.read_sql_query(avg_spend_query, conn).iloc[0, 0]\n",
    "print(f\"--- Answer 4.2: Average 3-Month Spend of Customers ---\")\n",
    "print(f\"{avg_spend}\\n\")\n",
    "\n",
    "\n",
    "# Step 4: Find the average conversion rate for these offers over the last 30 days (Answer 4.3)\n",
    "recent_ctr_query = f\"\"\"\n",
    "SELECT\n",
    "    offer_id,\n",
    "    SUM(CASE WHEN offer_action = '1' THEN 1.0 ELSE 0.0 END) / COUNT(*) as recent_conversion_rate\n",
    "FROM\n",
    "    clickstream_final\n",
    "WHERE\n",
    "    offer_id IN ({top_10_ids_str})\n",
    "    AND event_dt BETWEEN '2023-10-08' AND '2023-11-07' -- Last 30 days from Nov 7\n",
    "GROUP BY\n",
    "    offer_id;\n",
    "\"\"\"\n",
    "df_recent_ctr = pd.read_sql_query(recent_ctr_query, conn)\n",
    "print(\"--- Answer 4.3: Recent Conversion Rate for Top 10 Offers ---\")\n",
    "print(df_recent_ctr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "221ccdb3-6961-404f-a92e-faaabefd31a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Key result files have been saved to the 'data_cleaned' folder.\n"
     ]
    }
   ],
   "source": [
    "# Create a new folder for our clean data\n",
    "import os\n",
    "if not os.path.exists('data_cleaned'):\n",
    "    os.makedirs('data_cleaned')\n",
    "\n",
    "# Save the main results from Q2, Q3, and Q4 into new CSV files\n",
    "result_2.to_csv('data_cleaned/question_2_results.csv', index=False)\n",
    "df_performance.to_csv('data_cleaned/question_3_results.csv', index=False)\n",
    "df_top_10.to_csv('data_cleaned/question_4_top_10_offers.csv', index=False)\n",
    "\n",
    "print(\"Key result files have been saved to the 'data_cleaned' folder.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57929f49-4742-41dc-a172-c0651e4ed618",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
